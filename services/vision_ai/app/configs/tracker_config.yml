%YAML:1.0
################################################################################
# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
#
# Permission is hereby granted, free of charge, to any person obtaining a
# copy of this software and associated documentation files (the "Software"),
# to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense,
# and/or sell copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
# DEALINGS IN THE SOFTWARE.
################################################################################

NVDCF:
  BaseConfig:
    minDetectorConfidence: 0   # If the confidence of a detector bbox is lower than this, then it won't be considered for tracking

  TargetManagement:
    enableBboxUnClipping: 1   # In case the bbox is likely to be clipped by image border, unclip bbox
    maxTargetsPerStream: 150  # Max number of targets to track per stream. Recommended to set >10. Note: this value should account for the targets being tracked in shadow mode as well. Max value depends on the GPU memory capacity  

    # [Creation & Termination Policy]
    minIouDiff4NewTarget: 0.5   # If the IOU between the newly detected object and any of the existing targets is higher than this threshold, this newly detected object will be discarded.
    minTrackerConfidence: 0.7   # If the confidence of an object tracker is lower than this on the fly, then it will be tracked in shadow mode. Valid Range: [0.0, 1.0]
    probationAge: 3 # If the target's age exceeds this, the target will be considered to be valid.
    maxShadowTrackingAge: 9000   # Max length of shadow tracking. If the shadowTrackingAge exceeds this limit, the tracker will be terminated.
    earlyTerminationAge: 1      # If the shadowTrackingAge reaches this threshold while in TENTATIVE period, the target will be terminated prematurely.
    
  TrajectoryManagement:
    useUniqueID: 0   # Use 64-bit long Unique ID when assignining tracker ID.
    enableReAssoc: 1    # Enable Re-Assoc

    # [Re-Assoc: Motion-based]  
    minTrajectoryLength4Projection: 20  # min trajectory length required to make projected trajectory
    prepLength4TrajectoryProjection: 10  # the length of the trajectory during which the state estimator is updated to make projections
    trajectoryProjectionLength: 90  # the length of the projected trajectory

    # [Re-Assoc: Trajectory Similarity]
    minTrackletMatchingScore: 0.5   # min tracklet similarity score for matching
    maxAngle4TrackletMatching: 30   # max angle difference for tracklet matching [degree]
    minSpeedSimilarity4TrackletMatching: 0.2 # min speed similarity for tracklet matching
    minBboxSizeSimilarity4TrackletMatching: 0.6 # min bbox size similarity for tracklet matching  
    maxTrackletMatchingTimeSearchRange: 50      # the search space in time for max tracklet similarity
    
  DataAssociator:
    dataAssociatorType: 0 # the type of data associator among { DEFAULT= 0 }
    associationMatcherType: 0 # the type of matching algorithm among { GREEDY=0, GLOBAL=1 }
    checkClassMatch: 1  # If checked, only the same-class objects are associated with each other. Default: true

    # [Association Metric: Thresholds for valid candidates]
    minMatchingScore4Overall: 0.0   # Min total score
    minMatchingScore4SizeSimilarity: 0.5  # Min bbox size similarity score
    minMatchingScore4Iou: 0.0       # Min IOU score
    minMatchingScore4VisualSimilarity: 0.2  # Min visual similarity score

    # [Association Metric: Weights]
    matchingScoreWeight4VisualSimilarity: 0.6  # Weight for the visual similarity (in terms of correlation response ratio)
    matchingScoreWeight4SizeSimilarity: 0.2    # Weight for the Size-similarity score
    matchingScoreWeight4Iou: 0.2   # Weight for the IOU score

  StateEstimator:
    stateEstimatorType: 2  # the type of state estimator among { DUMMY=0, SIMPLE=1, REGULAR=2 }

    # [Dynamics Modeling]
    processNoiseVar4Loc: 2.0    # Process noise variance for bbox center
    processNoiseVar4Size: 1.0   # Process noise variance for bbox size
    processNoiseVar4Vel: 0.1    # Process noise variance for velocity
    measurementNoiseVar4Detector: 4.0    # Measurement noise variance for detector's detection
    measurementNoiseVar4Tracker: 16.0    # Measurement noise variance for tracker's localization
    
  VisualTracker:
    visualTrackerType: 1 # the type of visual tracker among { DUMMY=0, NvDCF=1 }

    # [NvDCF: Feature Extraction]
    useColorNames: 1     # Use ColorNames feature
    useHog: 1            # Use Histogram-of-Oriented-Gradient (HOG) feature  
    featureImgSizeLevel: 5  # Size of a feature image. Valid range: {1, 2, 3, 4, 5}, from the smallest to the largest
    searchRegionPaddingScale: 3
    featureFocusOffsetFactor_y: -0.2 # The offset for the center of hanning window relative to the feature height. The center of hanning window would move by (featureFocusOffsetFactor_y*featureMatSize.height) in vertical direction

    # [NvDCF: Correlation Filter]
    filterLr: 0.075 # learning rate for DCF filter in exponential moving average. Valid Range: [0.0, 1.0]
    filterChannelWeightsLr: 0.1 # learning rate for the channel weights among feature channels. Valid Range: [0.0, 1.0]
    gaussianSigma: 0.75 # Standard deviation for Gaussian for desired response when creating DCF filter [pixels] 
  
  ReID:
    reidType: 3    # The type of reid among { DUMMY=0, NvDEEPSORT=1, Reid based reassoc=2, both NvDEEPSORT and reid based reassoc=3}

    # [Reid Network Info]
    batchSize: 100    # Batch size of reid network
    workspaceSize: 1000    # Workspace size to be used by reid engine, in MB
    reidFeatureSize: 128    # Size of reid feature
    reidHistorySize: 100    # Max number of reid features kept for one object
    inferDims: [128, 64, 3]    # Reid network input dimension CHW or HWC based on inputOrder
    networkMode: 0    # Reid network inference precision mode among {fp32=0, fp16=1, int8=2 }

    # [Input Preprocessing]
    inputOrder: 1    # Reid network input order among { NCHW=0, NHWC=1 }. Batch will be converted to the specified order before reid input.
    colorFormat: 0    # Reid network input color format among {RGB=0, BGR=1 }. Batch will be converted to the specified color before reid input.
    offsets: [0.0, 0.0, 0.0]    # Array of values to be subtracted from each input channel, with length equal to number of channels
    netScaleFactor: 1.0000    # Scaling factor for reid network input after substracting offsets
    keepAspc: 1    # Whether to keep aspc ratio when resizing input objects for reid

    # [Paths and Names]
    inputBlobName: "images"    # Reid network input layer name
    outputBlobName: "features"    # Reid network output layer name
    uffFile: "/opt/nvidia/deepstream/deepstream/samples/models/Tracker/mars-small128.uff"    # Absolute path to reid network uff model
    modelEngineFile: "/opt/nvidia/deepstream/deepstream/samples/models/Tracker/mars-small128.uff_b100_gpu0_fp32.engine"    # Engine file path